---
layout: default
---

# 嵌入式AI 双周简报 (2017-10-03)

## 业界新闻
- [ARM 授权费用太贵，科技巨头欲转向开源架构 RISC-V | 雷锋网](https://www.leiphone.com/news/201805/8Nubo2qqdS7P8YRD.html?viewType=weixin)<br />
简评：IBM、NXP、西部数据、英伟达、高通、三星、谷歌、华为等 100 多家科技公司加入 RISC-V 阵营。
- [这是自由奔跑、自主导航的波士顿动力机器人 | The Verge](https://mp.weixin.qq.com/s/Mv6u5z_dzi6WRsk6KuAk6Q)<br />
简评：波士顿动力公司的机器人在每一段视频中的表现都非常自然且令人惊叹，今天该公司又在 YouTube 网站上发布了两个视频片段，展示了 Atlas 和 SpotMini 机器人的最新进展。
- [AI算力需求6年增长30万倍、3.5月翻一番 | OpenAI](https://mp.weixin.qq.com/s/b8R38i6Z9Vlr3FVMbiIexQ)<br />
简评：人工智能技术近年来的发展不仅仰仗于大数据，更是计算机芯片算力不断增强的结果。然而，如果 AI 算力需求的增长速度大大超过了芯片算力的进步，我们又该怎么办？这种担心似乎正在成为现实。根据 OpenAI 最新的分析，近年来人工智能训练任务所需求的算力每 3.43 个月就会翻倍，这一数字大大超越了芯片产业长期存在的摩尔定律（每 18 个月芯片的性能翻一倍）。
- [微软收购伯克利创业公司Semantic Machines：探索语音交互技术新前沿 | 机器之心](https://mp.weixin.qq.com/s/bS95_dxVeptCN_xTf-c8DQ)<br /> 
简评：微软宣布收购由 UC Berkeley 教授 Dan Klein 与斯坦福大学教授 Percy Liang 等人共同创立的对话系统创业公司 Semantic Machines。这家公司的技术或许将在语音合成、深度学习和自然语言处理等方面帮助微软与亚马逊 Alexa、苹果 Siri 和三星 Bixby 进行竞争。
- [VALSE 2018年度进展报告 | 深度神经网络加速与压缩](https://mp.weixin.qq.com/s/IPN6YFMUTYQkUDaASUVB0g)<br />
简评：本文介绍了深度神经网络加速和压缩最近一年的进展和趋势。
- [黄金时代 |StarryHeavensAbove](https://mp.weixin.qq.com/s/Mb0CzNZmDU84WV6A47Bcig)<br />
简评：今年的图灵奖得主John L. Hennessy和David A. Patterson即将在ISCA2018上做个讲演，题目是“A New Golden Age for Computer Architecture: Domain-Specific Hardware / Software Co-Design, Enhanced Security, Open Instruction Sets, and Agile Chip Development”[1]。而在IEEE Micro上，Google Brain的Jeff Dean, David Patterson和Cliff Young发表的文章“A New Golden Age in Computer Architecture: Empowering the Machine- Learning Revolution”[2]，从另一个视角提出了计算机体系结构的”黄金时代“。不同的角度，反映了不同的思考。
- [Google TPU3 看点 | StarryHeavensAbove](https://mp.weixin.qq.com/s/b22p26_delWfSpy9kDJKhA)<br />
简评：Google在I/O大会上发布了TPU3，虽然目前详细信息不多，但下面几点还是值得讨论：8倍性能；快速迭代；云服务和Benchmark。
- [ARM中国成立，中国芯的救星来了 | 菁英范](https://mp.weixin.qq.com/s/wth4hMmMQFl8RqY992pAAg)<br />
简评：，ARM中国合资公司已于4月底正式运营，中方投资者占股51%，ARM占股49%，这家新公司将接管ARM在国内的所有业务。考虑到上个月国内因为某兴事件才全国沸腾了一番，此时开始正式运营，可谓一个“完美时机”。
- [中星微夺冠国际人工智能算法竞赛，目标检测一步法精度速度双赢| 新智元](https://mp.weixin.qq.com/s/Ck_GDv1Xo-YMZcu-00gTOA)<br />
简评：中星微把实际安防项目经验应用到PASCAL VOC数据集，并成功在一步法（one-stage）算法中取得了第一名的好成绩。
- [专为深度学习而生的 Tensor Core 到底是什么？| 机器之心](https://mp.weixin.qq.com/s/2-eMxUZ_5F_mNG2sO7HcVQ)<br />
简评：大规模深度学习应用的开发对性能有很高的需求，作为深度学习加速器 GPU 硬件的核心供应商，英伟达一直在不断创新以满足 AI 社区对计算性能的需求。近日，英伟达开发者博客发文介绍了 Volta Tensor Core GPU 在 AI 性能提升上的里程碑进展。


## 论文

- [[1804.06882]A Real-Time Object Detection System on Mobile Devices ](https://arxiv.org/pdf/1804.06882.pdf)<br />
简评：已有的在移动设备上执行的深度学习模型例如 MobileNet、 ShuffleNet 等都严重依赖于在深度上可分离的卷积运算，而缺乏有效的实现。在本文中，来自加拿大西安大略大学的研究者提出了称为 PeleeNet 的有效架构，它没有使用传统的卷积来实现。PeleeNet 实现了比目前最先进的 MobileNet 更高的图像分类准确率，并降低了计算成本。研究者进一步开发了实时目标检测系统 Pelee，以更低的成本超越了 YOLOv2 的目标检测性能，并能流畅地在 iPhone6s、iPhone8 上运行。
- [Training and Inference with Integers in Deep Neural Networks](https://openreview.net/forum?id=HJGXzmspb)<br />
简评：清华大学类脑计算研究中心博士生吴双的论文被 ICLR2018 收录并在会上做口头报告。迄今为止，这是中国作为第一署名单位里唯一一篇被 ICLR 会议收录的口头报告文章。该报告主要探讨如何实现对全离散化深度神经网络进行训练和推理，便于部署到嵌入式设备中。
- [[1805.07008] Hierarchical Reinforcement Learning with Deep Nested Agents](https://arxiv.org/abs/1805.07008)<br />
简评：深度分层强化学习受到了广泛关注，因为它能够在具有挑战性的环境中产生最先进的结果，在这种环境中，无等级的框架无法学习有用的政策。然而，随着问题域变得更加复杂，深层的分层强化学习会变得低效，导致更长的收敛时间和糟糕的性能。我们引入深层嵌套代理框架，它是深度分层强化学习的一种变体，其中来自主代理的信息被传播到低级嵌套代理。
- [[1805.05373] DeepEM: Deep 3D ConvNets With EM For Weakly Supervised Pulmonary Nodule Detection](https://arxiv.org/abs/1805.05373)<br />
简评：为了训练深度神经网络来检测肺部计算机断层扫描（CT）图像中的肺结节，目前的做法是在许多CT图像上手动标记结节的位置和大小，以构建足够大的训练数据集，这是昂贵且困难的规模。另一方面，电子病历（EMR）包含大量关于每幅医学图像内容的部分信息。在这项工作中，我们探索如何挖掘这个庞大的，但目前尚未开发的数据源来改善肺结节检测。文章建议DeepEM，一种新的深度3D ConvNet框架增强了期望最大化（EM），用于挖掘EMR中用于肺结节检测的弱监督标签。
- [[1805.03988] ABMOF: A Novel Optical Flow Algorithm for Dynamic Vision Sensors](https://arxiv.org/abs/1805.03988)<br />
简评：本文提出了一种事件驱动的OF算法，称为自适应块匹配光流（ABMOF）。ABMOF使用累积DVS事件的时间片。时间片根据输入事件和OF结果自适应旋转。与诸如基于梯度的OF等其他方法相比，ABMOF可以在紧凑的逻辑电路中有效地实现。结果表明，ABMOF达到了与传统标准（如Lucas-Kanade（LK））相当的准确度。
- [[1805.05809]Efficient end-to-end learning for quantizable representations](https://arxiv.org/abs/1805.05809)<br />
简评：本文提出一个直接学习可量化嵌入表示和端到端稀疏二进制散列码的问题，它可以用来构造一个高效的哈希表，不仅在数据数量上体现了显著的搜索量减少，而且实现了TH的状态
- [[1805.06150] FollowNet: Robot Navigation by Following Natural Language Directions with Deep Reinforcement Learning](https://arxiv.org/abs/1805.06150)<br />
简评：本文讲述了一个端到端可微的神经架构，用于学习多模态导航策略。
- [[1805.06361]Object detection at 200 Frames Per Second ](https://arxiv.org/abs/1805.06361)<br />
简评：本文提出了一种高效、快速的目标探测器，可以每秒处理数百帧。为了实现这个目标，本文研究了对象检测框架的三个主要方面：网络架构、损失函数和培训数据（标记和未标记）。
- [[1805.05286]AMR Parsing as Graph Prediction with Latent Alignment ](https://arxiv.org/abs/1805.05286)<br />
简评：AMR解析具有挑战性，部分原因是图中的节点和相应句子中的单词之间缺少带注释的对齐。本文引入了一个神经解析器，它将对齐看作是概念、关系和对齐的联合概率模型中的潜在变量。


## 开源项目

- [MXNet开放支持Keras，高效实现CNN与RNN的分布式训练](https://mp.weixin.qq.com/s/CgxrvNfyu35SMvWBAt-5kg)<br />
简评：AWS 发布博客宣布 Apache MXNet 已经支持 Keras 2，开发者可以使用 Keras-MXNet 深度学习后端进行 CNN 和 RNN 的训练，安装简便，速度提升，同时支持保存 MXNet 模型。
- [DLL：一个炙手可热的快速深度神经网络库](https://github.com/wichtounet/dll)<br />
简评：DLL 是一个旨在提供由 C++实现的受限玻尔兹曼机（RBM）和深度信念网络（DBN）及其卷积版本的软件库，由瑞士 University of Applied Science of Western Switzerland、弗里堡大学的研究者共同提出。与常用的深度学习框架类似，它还支持更多标准的神经网络。目前，该工具已开发至 1.1 版本。
- [A semi automatic Image Annotation Tool](https://virajmavani.github.io/saiat/)<br />
简评：一个新的图像标注工具，它包含了一个现有的先进的艺术对象检测模型，叫做视网膜网，以显示80个通用对象类的建议，减少了用于注释图像的人工工作量。
- [医学图像深度学习应用训练营资料](https://github.com/bayesianio/applied-dl-2018)<br />
简评：深度肿瘤学12个应用深度学习实验室。
- [Go AI program which implement the AlphaGo Zero paper](https://github.com/Tencent/PhoenixGo)<br />
简评：腾讯发布的AlphaGo Zero复现围棋AI程序。
- [GluonNLP — 自然语言处理的深度学习工具包](https://zhuanlan.zhihu.com/p/36708892)<br />
简评：基于MXNet的深度学习自然语言处理包GluonNLP。

## 博文

- [AutoTVM：让AI来编译优化AI系统底层算子 | 陈天奇](https://zhuanlan.zhihu.com/p/37181530)<br />
简评：预计两周左右时间开放。
- [用机器学习构建O(N)复杂度的排序算法，可在GPU和TPU上加速计算 | 机器之心](https://mp.weixin.qq.com/s/qos7VRFP7uYZ6Qt83KiPhw)<br />
简评：排序一直是计算机科学中最为基础的算法之一，从简单的冒泡排序到高效的桶排序，我们已经开发了非常多的优秀方法。但随着机器学习的兴起与大数据的应用，简单的排序方法要求在大规模场景中有更高的稳定性与效率。中国科技大学和兰州大学等研究者提出了一种基于机器学习的排序算法，它能实现 O(N) 的时间复杂度，且可以在 GPU 和 TPU 上高效地实现并行计算。这篇论文在 Reddit 上也有所争议，我们也希望机器学习能在更多的基础算法上展现出更优秀的性能。
- [ARM7、ARM9和ARM11的区别 | 嵌入式资讯精选](https://mp.weixin.qq.com/s/ouq2O5y7RXpZze8l7-Qnvg)<br />
简评：本文从流水线到处理器的各个层面详细解读了三者之间的区别。
- [读懂FPGA中的除法运算及初识AXI总线 | 嵌入式资讯精选](https://mp.weixin.qq.com/s/GRqtZG8C_aDRE7CwXRUhJA)<br />
简评：FPGA中的硬件逻辑与软件程序的区别，相信大家在做除法运算时会有深入体会。若其中一个操作数为常数，可通过简单的移位与求和操作代替，但用硬件逻辑完成两变量间除法运算会占用较多的资源，电路结构复杂，且通常无法在一个时钟周期内完成。因此FPGA实现除法运算并不是一个“/”号可以解决的。
- [Cortex-M处理器跑得了Linux吗？| ZLG致远电子]()<br />
简评：单片机与应用处理器的核心区别到底是什么呢？是核心主频的差异？还是Linux系统的支持？又或者是处理器的架构？本文将以NXP的Cortex-M系列为例做简要介绍。
- [如何评测AI系统？|  StarryHeavensAbove](https://mp.weixin.qq.com/s/N-X82yjS3rBrZSO8ZNdnDw)<br />
简评：随着MLPerf走进大家的视野，AI系统（这里指完成AI任务的软硬件系统）的Benchmark这个话题备受关注。从目前的进展来看，对于机器学习训练（Training）系统，MLPerf可以说基本解决了对比评测的问题；而对于推断（Inference）系统来说，设计Benchmark非常困难，很多问题目前还看不到答案。
- [深度卷积神经网络演化历史及结构改进脉络 | 新智元](https://mp.weixin.qq.com/s/28GtBOuAZkHs7JLRVLlSyg)<br />
简评：自2012年AlexNet网络出现之后，最近6年以来，卷积神经网络得到了急速发展，在很多问题上取得了当前最好的结果，是各种深度学习技术中用途最广泛的一种。在本文中将为大家回顾和总结卷积神经网络的整个发展过程。
- [OpenCV条码/二维码识别](https://www.pyimagesearch.com/2018/05/21/an-opencv-barcode-and-qr-code-scanner-with-zbar/)<br />
简评：本文讲述了如何用OpenCV识别条码和二维码。
- [VGG16 Transfer Learning - Pytorch | Kaggle](https://www.kaggle.com/carloalbertobarbano/vgg16-transfer-learning-pytorch/code)<br />
简评：VGG16迁移学习示例。

----

Editor: 王建章、袁帅

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/2.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/">知识共享署名-相同方式共享 2.0 通用许可协议</a>进行许可。
