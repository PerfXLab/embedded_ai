---
layout: default
---

# 嵌入式AI 双周简报 (2018-01-31)

## 业界新闻

- [AAAI 2018 | 阿里巴巴提出极限低比特神经网络，用于深度模型压缩和加速 | 机器之心](http://mp.weixin.qq.com/s/_V1MTtgaWb2S6mZA37fdxA)</br>
简评：国际知名的人工智能学术会议 AAAI 2018 即将于 2 月份在美国新奥尔良举办，据机器之心了解，阿里巴巴共有 11 篇论文被接收。在介绍的这篇论文中，阿里巴巴提出利用ADMM算法学习极限低比特神经网络的架构。
- [英特尔暂停发放CPU补丁， Linux之父怒批“Spectre补丁是彻底的垃圾” |  Linuxer](http://mp.weixin.qq.com/s/YXgUHdt5Je6rJ_N24PIcKA) <br />
简评：英特尔周一表示用户应当停止在受影响的设备上，部署上个月由安全人员发现的芯片安全Meltdown和Spectre漏洞补丁，因为目前发现了超出预期的重启问题以及其他“不可预测”的系统行为。
- [亚马逊无人商店开业了，我们到现场排了队还来了一次花式测评 | 机器之心](http://mp.weixin.qq.com/s/_LczoTOTD3KbSrVhYZO3iw)<br />
简评：文章作者亲身体验亚马逊无人商店，并且通过购物APP做出各种测试。
- [三星将推首款AI芯片NPU，性能超华为苹果，智能终端AI芯大PK| 新智元](http://mp.weixin.qq.com/s/igG30KpJ81T0B5qhQKTHYg)<br />
简评：据外媒爆料，三星已经接近完成一款AI芯片的研发，其性能已经堪比苹果的A11和华为麒麟970，三星极有可能在2月25日举行的MWC 2018大会上发布Galaxy S9的同时，展示其新AI技术的能力。
- [清华研发出可支持神经网络的芯片 | 警用科技](http://mp.weixin.qq.com/s/h4EvTfjHmEvLAhtnpXJ0uw)<br />
简评：清华大学研究团队取得重大突破，研发出支持神经网络的芯片，可运用于使用电池的小型设备。


## 论文
- [1801.06287] [What Does a TextCNN Learn?](https://arxiv.org/abs/1801.06287)</br>
简评：TextCNN是一个用于文本的卷积神经网络，它是一种有用的深度学习算法，用于句子分类任务，如情绪分析和问题分类。然而，神经网络长期以来被称为黑匣子，因为解释它们是一项具有挑战性的任务。研究人员已经开发出了一些工具来通过深度可视化来理解CNN的图像分类，但是对于深度文本的研究仍然不够。在本文中，我们试图了解一个TextCNN在两个经典的NLP数据集上学习的内容。我们的工作侧重于不同的卷积的功能。
- [1801.06434] [EffNet: An Efficient Structure for Convolutional Neural Networks](https://arxiv.org/abs/1801.06434)</br>
简评：随着越来越多的卷积神经网络对客户的产品需要出现的模型可以有效地运行在嵌入式的应用，手机硬件。因此，精简的模型已经成为一个热门的研究课题，有多种不同的方法，从二进制网络到修正卷积层。我们为后者提供了贡献，并提出了一种新的卷积块，大大减少了计算负担，同时超过了目前的最先进的。我们的模型，称为effnet，优化模型是苗条的开始，是为了解决现有的模型，如MobileNet和ShuffleNet的问题。
- [1801.07606] [Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning](https://arxiv.org/abs/1801.07606)</br>
简评：机器学习中的许多有趣的问题正在用新的深层学习工具重新审视。基于图的半监督学习，最近的一个重要的发展是图卷积网络（GCN），从而很好地整合当地的顶点的特征及其在卷积层图的拓扑结构。虽然与其他国家的最先进的方法与模型相比，毫不逊色，其机制尚不清楚，仍需要大量的标注数据验证和模型选择。在本文中，我们更深入认识GCN模式和解决其根本的限制。首先，我们发现GCN图形卷积模型实际上是拉普拉斯平滑的一种特殊形式，其中的主要原因是GCNs的工作，但同时也带来了潜在的问题在许多层平滑卷积。其次，针对浅的GCN架构模型的限制，我们提出了协同训练和自我训练，GCNs的训练方法。我们的方法显着提高GCN与极少数标签学习，并免除他们需要确认额外的标签。大量的基准测试证实了我们的理论和建议。
- [1801.06700] [A Deep Reinforcement Learning Chatbot (Short Version)](https://arxiv.org/abs/1801.06700)</br>
简评：milabot能够通过语音和文本的流行话题的人交谈。该系统由自然语言生成和检索模型组成，包括神经网络和基于模板的模型。采用强化学习的众包数据与真实的用户交互，系统已经被训练来选择一个合适的模型的整体反应。该系统通过与现实世界用户进行了B／B测试，其性能显著优于其他系统。结果突出了耦合集成系统与深强化学习作为一个富有成效的发展现实世界，开放域会话代理的潜力。
- [1801.07829] [Dynamic Graph CNN for Learning on Point Clouds](https://arxiv.org/abs/1801.07829)</br>
简评：文章提出了一种新的神经网络模块称为edgeconv适合美国有线电视新闻网的高级任务包括对点云的分类和分割。edgeconv是可微的，可以插入到现有的体系结构。相比现有的模块的操作主要是在外部空间或处理每个点独立，EdgeConv有几个有吸引力的特性：它采用了局部邻域信息；它可以堆叠或反复应用学习全局形状特性；在多层系统的亲和力在特征空间中捕捉语义特征在原始嵌入的潜在的长距离。在提出这一模块，我们提供广泛的评价和分析，揭示edgeconv捕捉和利用细粒度的点云的几何性质。该方法实现了国家的最先进的性能标准的基准测试，包括modelnet40和s3dis。
- [1801.06867] [Scene recognition with CNNs: objects, scales and dataset bias](https://arxiv.org/abs/1801.06867)</br>
简评：该论文提出了一个替代的方法，考虑到规模，从而产生显著的认识收益。由ImageNet CNNs和地方CNN在不同的尺度上我们发现，在不同的尺度范围的响应分析，所以使用同一网络的所有尺度的数据偏差造成的性能限制诱导。因此，采用特征提取的每个特定的规模（即特定尺度的CNN）是提高识别的关键，因为场景中的对象有其特定范围的尺度。实验结果表明，识别精度在很大程度上取决于规模，这简单而精心选择的多尺度组合ImageNet CNNs和地方CNN，可以推动国家的最先进的识别精度sun397达66.26%（甚至70.17%与深层结构，与人的行为）。


## 开源项目

- [romulus914/CNN_VGG19_verilog: Convolution Neural Network of vgg19 model in verilog](https://github.com/romulus914/CNN_VGG19_verilog)</br>
简评：verilog中vgg19模型的卷积神经网络。
- [cliffordwolf/picorv32: PicoRV32 - A Size-Optimized RISC-V CPU](https://github.com/cliffordwolf/picorv32)</br>
简评：PicoRV32是实现RISC-V RV32IMC指令集的CPU内核。它可以配置为RV32E，RV32I，RV32IC，RV32IM或RV32IMC内核，还可以选择包含一个内置的中断控制器。
- [azonenberg/openfpga: Open FPGA tools](https://github.com/azonenberg/openfpga)</br>
简评：更新了v0.2散热板的原理图。
- [Detectron精读系列之一：学习率的调节和踩坑 | 机器之心](http://mp.weixin.qq.com/s/kL1bhjdTc1wyYEL4KJqDpg)</br>
简评：Detectron 开源，文章作者提前踩坑并展示学习率的调节。
- [Uber提出SBNet：利用激活的稀疏性加速卷积网络 | Uber](http://mp.weixin.qq.com/s/xCzS7sYMFmk5K4ClB1I2YQ) <br />
简评：Uber 的研究人员提出了一种可以在改善检测准确度的同时极大提升速度的算法 SBNet 并在其工程开发博客上对该研究进行了介绍。另外，本项目的代码也已在 GitHub 上发布。
- [十倍模型计算时间仅增20%：OpenAI开源梯度替换插件 | GitHub](http://mp.weixin.qq.com/s/glwjwXNNoMYBmhgwEcpUeg)</br>
简评： OpenAI 研究员 Tim Salimans 和 Yaroslav Bulatov 联合开发的工具包，你可以权衡计算力和内存的使用，从而使你的模型更合理地占用内存。对于前馈模型，我们能够借助该工具把大 10 多倍的模型放在我们的 GPU 上，而计算时间只增加 20%。
- [TensorFlow正式发布1.5.0，支持CUDA 9和cuDNN 7，双倍提速](http://mp.weixin.qq.com/s/ilBcSQ5RGAx9Fp7oSri3sA)</br>
简评：TensorFlow今天正式发布了1.5.0版本，支持CUDA 9和cuDNN 7，进一步提速。并且，从1.6版本开始，预编译二进制文件将使用AVX指令，这可能会破坏老式CPU上的TF.

## 博文

- [细读EETimes的AI芯片文章 | StarryHeavensAbove](http://mp.weixin.qq.com/s/BPoCM7H44dns9y-Ul0jMPw)<br />
简评：“AI Silicon Preps for 2018 Debuts”，作者抽取部分文章介绍了和AI芯片相关的各种问题。
- [浅析图像视频类AI芯片的灵活度 | StarryHeavensAbove ](https://mp.weixin.qq.com/s/wivFTy3Tj6Ahc5XO6-FX2w)<br />
简评：本文通过列举目前图像视频类的典型算法、典型网络结构、典型平台和接口等方面来分析AI芯片的灵活度范围。
- [](http://mp.weixin.qq.com/s/6ksL9p1Gmnrd2HahU3KniQ)</br>
简评：本文原文链接主要介绍了ARM的攒机方法文章主要精简的拆解各个设备市场的技术重点。
- [语音及文本类AI芯片的需求分析 | 机器之心](http://mp.weixin.qq.com/s/cfqnLYZSxJhtsgtrydx02A)</br>
简评：文章作者分别深度分析了语音文本类深度学习和AI芯片的需求。
- [【计算机视觉必读干货】图像分类、定位、检测，语义分割和实例分割方法梳理](http://mp.weixin.qq.com/s/oe8Zcv3EecDV2OUl9qejCA)</br>
简评：本文作者来自南京大学计算机系机器学习与数据挖掘所（LAMDA），本文直观系统地梳理了深度学习在计算机视觉领域四大基本任务中的应用，包括图像分类、定位、检测、语义分割和实例分割。
- [PTGAN：针对行人重识别的生成对抗网络 | PaperDaily #36](http://mp.weixin.qq.com/s/rf-pGfkQFK3abkOLEEVOeA)</br>
简评：本文提出了一种针对于行人重识别的生成对抗网络 PTGAN，使用 GAN 将一个数据集的行人迁移到另外一个数据集。
- [如何让手机快速运行AI应用？这有份TVM优化教程 | 量子位](http://mp.weixin.qq.com/s/j-z_xg8FqfAxGcMNISirdQ) <br />
简评：TVM通过引入一个统一的IR堆栈来解决不同硬件平台的部署问题。使用TVM/NNVM可以为ARM Mali GPU生成高效内核，并且进行端到端的编译。
- [利用视频物体跟踪实现移动端Video Tagging](http://mp.weixin.qq.com/s/nwXN0YdVviI43E4IyUuJ3A) <br />
简评：文章阐述了利用计算机视觉中经典的视频目标跟踪算法来实现轻量级的视频tagging功能，从而可以生成更加丰富，个性化的视频内容。


Editor: 王建章、袁帅

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/2.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/">知识共享署名-相同方式共享 2.0 通用许可协议</a>进行许可。
