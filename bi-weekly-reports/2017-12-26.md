---
layout: default
---

# 嵌入式AI 双周简报 (2017-12-26)

## 业界新闻

- [地平线余凯发布嵌入式视觉芯片中国芯“征程”与“旭日” | 新智元](https://mp.weixin.qq.com/s?timestamp=1514257509&src=3&ver=1&signature=FfXR2-8lg8yx0vXHlibMXwDuJ6AmuXxHls6MtNB*YXKqrvKPYGly1ZA4ngzVFoxnMn7hmvIChDCj3rC5oItBHkpckUkgSEiZCMoy03mY-CCQaLVXQyHxNQkKTvRuUepY1j2HMQLqD3dM8yoDyFER6sbQ1dINRVLthbAf-gILFnk=)<br />
简评：这两款芯片，芯片性能可达到1Tops，实时处理1080P@30帧，每帧可同时对200个目标进行检测、跟踪、识别。 典型功耗做到1.5w。
- [国家“千人”王中风教授：如何满足不同应用场景下深度神经网络模型算力和能效需求 | 新智元](https://mp.weixin.qq.com/s?timestamp=1514257509&src=3&ver=1&signature=FfXR2-8lg8yx0vXHlibMXwDuJ6AmuXxHls6MtNB*YXKqrvKPYGly1ZA4ngzVFoxnMn7hmvIChDCj3rC5oItBHnBdn8wMHNN3uxGyw2K0SdQ81-*CzYfftcGcKO52umn8g3YOrMJxVoLSUbXOaXDxxZR6Y9TgLwP4Bw0tSGdBxLw=)<br />
简评：本文探讨了如何在算法层面运用量化、剪枝等方法进行模型压缩，以及设计适应于不同应用场景的高能效神经网络计算芯片/架构，从而满足深度神经网络在不同的应用场景下的算力能效需求。
- [AAAI 2018商汤提出强兼容深度网络加速新方法 | 新智元](https://mp.weixin.qq.com/s?timestamp=1514257509&src=3&ver=1&signature=FfXR2-8lg8yx0vXHlibMXwDuJ6AmuXxHls6MtNB*YXKqrvKPYGly1ZA4ngzVFoxnMn7hmvIChDCj3rC5oItBHo63fQsLgo*kUaBW8XbQzMSrIQjSMd0mhUVkHHih5SOLScHYHbBx8Hnb6vjxvhH1xib97160ueAj9hVNhwVOV2A=)<br />
简评：中山大学、哈尔滨工业大学、桂林电子大学，香港理工大学以及商汤科技公司联合研究团队提出基于类小波自编码机的深度网络加速法。该方法首先通过一个可学习的类小波自编码机（Wavelet-like Auto-Encoder, WAE），把输入图片分解成两个低分辨率的小图，再以小图替代大图输入到深度网络，从而达到加速的效果。该方法优势还在于，不需要改动原来网络的结构，故可以兼容现有的深度神经网络，有极好的普适性。
- [谷歌云提出渐进式神经架构搜索：高效搜索高质量CNN结构 | 机器之心](https://mp.weixin.qq.com/s?timestamp=1514258116&src=3&ver=1&signature=FfXR2-8lg8yx0vXHlibMX-LrfuW44JWbxudqhekxZHWOXOjBwj3jAIJobOFuBbC**M3KZChNa6cSHLZ9cIu4Bq1KG5yasXZt1jt2RX2GRmzIZoIbVo8SNYiLFoLcis5WS19yTxNmnIlDf9mhb-cc4v4caSPlpgVd9T112GObN-U=)<br />
简评：该学习 CNN 结构的方法基于序列模型的优化（SMBO）策略，其中按复杂度逐渐增大的顺序搜索架构，同时学习一个用于引导该搜索的代理函数（surrogate function），类似于 A* 搜索。
- [为给定任务自动生成神经网络：MIT提出RNN架构生成新方法 | 机器之心](https://mp.weixin.qq.com/s?timestamp=1514257760&src=3&ver=1&signature=FfXR2-8lg8yx0vXHlibMX4Iq5rZwJkx6u9brWzwW58OiWij88J-VYzOF64lJBA8k-32edzoJrNPYBXMsjNrpdEJ7HhGThCRsRwktn0bqyv8HUOLWYQh*Abtb6jTNRkgjL39iWMvZhAILwC0QI48ByCk6XpQwtmEeUOW4a-jMSnA=)<br />
简评：MIT 研究人员最近提出的 RNN 架构自动生成方法使用了灵活的 DSL 搜索和强化学习，在语言建模和机器翻译等任务上表现良好。新方法可以让我们摆脱依靠直觉的费力模型设计方式，同时也大大扩展了循环神经网络的可能性空间。




## 开源项目

- [burningion/poor-mans-deep-learning-camera: Build a thin client deep learning camera with the Raspberry Pi, Flask, and YOLO](https://github.com/burningion/poor-mans-deep-learning-camera)
[[code](https://www.makeartwithpython.com/blog/poor-mans-deep-learning-camera/)]<br />
简评：
- [twitter/vireo: Vireo is a lightweight and versatile video processing library written in C++11](https://github.com//twitter/vireo)<br />
简评：
- [cgtuebingen/tensorpack-recipes: A collection of TensorPack implementations of recent deep learning approaches including pretrained models.](https://github.com//cgtuebingen/tensorpack-recipes)<br />
简评：
- [okdshin/instant: DNN Inference with CPU, C++, ONNX support: Instant](https://github.com//okdshin/instant)<br />
简评：
- [BoyuanJiang/Age-Gender-Estimate-TF: Face age and gender estimate using TensorFlow](https://github.com//BoyuanJiang/Age-Gender-Estimate-TF)<br />
简评：


## 论文

- [1712.05134] [Learning Compact Recurrent Neural Networks with Block-Term Tensor Decomposition](https://arxiv.org/abs/1712.05134) <br />
简评：RNN在解决序列建模，尤其是高维度的输入数据对应的很大模型，会有超大的参数量和训练时间，为解决该问题，作者提出更紧凑的结构：Block-Term tensor decomposition，该结构可降低模型参数的同时提升训练效率。相比tensor-train RNN（TT-RNN）和low-rank approximations，作者的方法在参数量更少的同时准确性更好。在视频动作识别、图像描述、图像生成三个任务中，作者的BT-RNN在准确率和收敛速度上都比TT-RNN、RNN有优势。在动作识别任务的UCF11数据集上，BT-LSTM的参数量仅为LSTM的1/17388，性能却高了15.6%。
- [1712.07316] [A Flexible Approach to Automated RNN Architecture Generation](https://arxiv.org/abs/1712.07316) [[blog](https://mp.weixin.qq.com/s?timestamp=1514257760&src=3&ver=1&signature=FfXR2-8lg8yx0vXHlibMX4Iq5rZwJkx6u9brWzwW58OiWij88J-VYzOF64lJBA8k-32edzoJrNPYBXMsjNrpdEJ7HhGThCRsRwktn0bqyv8HUOLWYQh*Abtb6jTNRkgjL39iWMvZhAILwC0QI48ByCk6XpQwtmEeUOW4a-jMSnA=)]<br />
简评：MIT 研究人员最近提出的 RNN 架构自动生成方法使用了灵活的 DSL 搜索和强化学习，在语言建模和机器翻译等任务上表现良好。新方法可以让我们摆脱依靠直觉的费力模型设计方式，同时也大大扩展了循环神经网络的可能性空间。
- [1712.04910] [FFT-Based Deep Learning Deployment in Embedded Systems](https://arxiv.org/abs/1712.04910) <br />
简评：作者提出基于FFT训练和推理的DNN模型，尤其适用于对于存储和计算能力有限的嵌入式平台，
- [1707.07012] [Learning Transferable Architectures for Scalable Image Recognition](https://arxiv.org/abs/1707.07012) [[code](https://github.com//titu1994/Keras-NASNet)]<br />
简评：为解决架构工程问题，作者提出一种基于数据集自动搜寻模型block的方法。作者用该方法基于CIFAR10数据集搜寻最佳block，之后将该block堆叠出的模型应用到ImageNet上。尽管没有直接在ImangeNet上进行最佳的block搜寻，但在ImageNet上top1和top5准确率分别达到82.7%和96.2%。相比最佳的人类设计的模型，该方法的top1准确率要领先1.2%的同时参数量减少28%。在检测任务的COCO数据集上，基于该方法搭建的网络在特征学习上要超过同样模型架构Faster-RCNN，性能高于4.0%达到43.1%的mAP。
- [1712.03351] [Peephole: Predicting Network Performance Before Training](https://arxiv.org/abs/1712.03351)<br />
简评：同样是解决模型设计的问题。作者提出在基于网络的架构，在训练前就预测网络性能的方法。作者将不同的层编码成向量并交给LSTM，利用RNN的表达优势可以预测各种不同网络架构的性能。作者实验证明，该方法预测出的模型性能和实验的结果一致。
- [1611.05162] [Net-Trim: Convex Pruning of Deep Neural Networks with Performance Guarantee](https://arxiv.org/abs/1611.05162)
[[code](https://github.com/DNNToolBox/Net-Trim-v1)] [[blog](https://www.ibm.com/blogs/research/2017/12/pruning-ai-networks/)]<br />
简评：作者提出一种用于模型剪枝的新方案——Net-Trim算法，该方法会对一个训练过的模型，将逐层地移除某些连接视为一个解决凸优化问题的过程。该过程会找保证该层输入和输出一致下的稀疏权重，此外作者提出基于该方法的并行和串行版本。两个版本后者得到的模型更轻量，但前者可以在分布式环境下使用。此外作者也给出了对剪枝前后模型的数学分析。


## 博文

- [Deep Learning Hardware Limbo | Tim Dettmers](http://timdettmers.com/2017/12/21/deep-learning-hardware-limbo/)<br />
简评：该文讲述了Intel、NVIDIA、AMD在过去以及未来几个月的深度学习硬件过渡期，重点分析了这三家在价格、生态上的特点和应对策略。
- [2017: What a Wonderful Year for AI | Intel Nervana](https://www.intelnervana.com/intel-ai-2017/)<br />
简评：英特尔AI团队对2017年在人工智能软件、硬件上的总结。
- [Deep Learning: Practice and Trends | Google 幻灯片](https://docs.google.com/presentation/d/e/2PACX-1vQMZsWfjjLLz_wi8iaMxHKawuTkdqeA3Gw00wy5dBHLhAkuLEvhB7k-4LcO5RQEVFzZXfS6ByABaRr4/pub?start=false&loop=false&delayms=60000&slide=id.g2a19ddb012_0_75) [[video](https://www.bilibili.com/video/av17078412/)] <br />
简评：深度学习实践与趋势幻灯片和视频。
- [Apps That Hint at a Fanciful Fake Future - MIT Technology Review](https://www.technologyreview.com/s/609235/apps-that-hint-at-a-fanciful-fake-future/) <br />
简评：AR应用
- [NVIDIA AI CITY CHALLENGE | NVIDIA](http://www.aicitychallenge.org/)<br />
简评：
- [A Startup Uses Quantum Computing to Boost Machine Learning | MIT Technology Review](https://www.technologyreview.com/s/609804/a-startup-uses-quantum-computing-to-boost-machine-learning/)<br />
简评：用量子计算加速机器学习(初创公司Rigetti将量子计算用于聚类)。
- [Keras and deep learning on the Raspberry Pi | PyImageSearch](https://www.pyimagesearch.com/2017/12/18/keras-deep-learning-raspberry-pi/)<br />
简评：
- [Fast INT8 Inference for Autonomous Vehicles with TensorRT 3 | Parallel Forall](https://devblogs.nvidia.com/parallelforall/int8-inference-autonomous-vehicles-tensorrt/)<br />
简评：
- [New App Turns Your Selfie Into a Personalized Emoji – NVIDIA Developer News Center](https://news.developer.nvidia.com/new-app-turns-your-selfie-into-a-personalized-emoji/)
[[app](https://www.mirror-ai.com/)]<br />
简评：




----

Editor: 张先轶、袁帅

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/2.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/">知识共享署名-相同方式共享 2.0 通用许可协议</a>进行许可。
